{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare model outputs of AICORE DL Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "# workaround buggy autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_props_from_config(config_file):\n",
    "    config = yaml.load(open(config_file), Loader=yaml.BaseLoader)\n",
    "    m = config['model']\n",
    "    try:\n",
    "        resume = config['resume'][1]\n",
    "    except:\n",
    "        resume = ''\n",
    "    return config, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals_from_dir(subdir):\n",
    "    basename = subdir.name\n",
    "    \n",
    "    df_tr = pd.read_csv(subdir / 'train.csv')\n",
    "    df_tr['basename'] = basename[:]\n",
    "    df_tr['type'] = 'train'\n",
    "    df_tr['region'] = basename.split('__')[2]\n",
    "    #df_list_tr.append(df_tr)\n",
    "    \n",
    "    \n",
    "    df_v = pd.read_csv(s / 'val.csv')\n",
    "    df_v['basename'] = basename[:]\n",
    "    df_v['type'] = 'val'\n",
    "    df_v['region'] = basename.split('__')[2]\n",
    "    #df_list_v.append(df_v)\n",
    "    \n",
    "    return df_tr, df_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats_from_logs(logdirs):\n",
    "    \n",
    "    df_list_tr = []\n",
    "\n",
    "    for s in logdirs:\n",
    "        try:\n",
    "            config_file = s / 'config.yml'\n",
    "            config, resume = get_props_from_config(config_file)\n",
    "            \n",
    "            df = pd.Series()\n",
    "            df['name'] = s.name\n",
    "            df['log_dir_path'] = s.absolute()\n",
    "            df['architecture'] = config['model']['architecture']\n",
    "            df['backbone'] = config['model']['encoder']\n",
    "            df['encoder_weights'] = config['model']['encoder_weights']\n",
    "            df['loss_function'] = config['loss_function']\n",
    "            #df['a_b'] = df['architecture'] + '_' + df['backbone']\n",
    "            df['resume'] = resume\n",
    "            df['stack_height'] = int(config['model_args']['stack_height'])\n",
    "            df['timestamp'] = datetime.datetime.strptime(config['run_info']['timestamp'], '%Y-%m-%d_%H-%M-%S')\n",
    "            df['learning_rate_scheduler'] = config['learning_rate_scheduler']\n",
    "            df['learning_rate'] = config['learning_rate']\n",
    "            df['augment_types'] = config['datasets']['train']['augment_types']\n",
    "            df['input_channels'] = int(config['model']['input_channels'])\n",
    "\n",
    "            train_csv =  pd.read_csv(s / 'train.csv')\n",
    "            tr_max = train_csv.max().add_prefix('tr_score_max_')\n",
    "            tr_05 = train_csv.sort_values(by='F1', ascending=False).iloc[4].add_prefix('tr_score_5th_')\n",
    "            tr_min = train_csv.min().add_prefix('tr_score_min_')\n",
    "\n",
    "            val_csv =  pd.read_csv(s / 'val.csv')\n",
    "            val_max = val_csv.max().add_prefix('val_score_max_')\n",
    "            val_05 = val_csv.sort_values(by='F1', ascending=False).iloc[4].add_prefix('val_score_5th_')\n",
    "            val_min = val_csv.min().add_prefix('val_score_min_')\n",
    "\n",
    "            df_tr = pd.concat([df, tr_max, tr_05, tr_min, val_max, val_05, val_min])\n",
    "            df_list_tr.append(df_tr)\n",
    "        except:\n",
    "            print(f\"Error on dataset: {s.name}\")\n",
    "            continue\n",
    "\n",
    "    df_out = pd.concat(df_list_tr, axis=1).T.reset_index()\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to open dir in explorer to connect !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your main logdir\n",
    "LOGDIR = Path(r'/isipd/projects/p_aicore_pf/initze/experiments')\n",
    "SUB_REGEX = '*/RTS*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = list(LOGDIR.glob(SUB_REGEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = load_stats_from_logs(subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show best 3 runs (by F1 validation score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stats.sort_values(by='val_score_5th_F1', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(df_stats,\n",
    "                #labels=dict(x=\"Day of Week\", y=\"Time of Day\", color=\"Productivity\"),\n",
    "                x=['val_score_max_F1', 'val_score_max_IoU'],\n",
    "                y=['name']\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_results(log_dir_path):\n",
    "    csv_train = log_dir_path / 'train.csv'\n",
    "    csv_val = log_dir_path / 'val.csv'\n",
    "\n",
    "    train = pd.read_csv(csv_train).add_suffix('_train')\n",
    "    val = pd.read_csv(csv_val).add_suffix('_val')\n",
    "\n",
    "    df = pd.concat([train, val], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_raw_results(df_stats.loc[4].log_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=df, x='Epoch_val', y=['F1_val', 'Precision_val', 'Recall_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
